\chapter{Introduction}
- motivation: why are stencil coputations important 
- problem: why is efficient implementation on cerebres difficult, what are the chances?

challenges:
- Cerebras uses \ac{csl} for the \ac{wse} chip. no compiler for higher level languages like stencil dsls to \ac{csl}
- also: prgoramming paradigm is vastly differnet. no shared memory. no cache. each \ac{pe} completely indendent from others.

-> needs hand crafted kernel/prgramm/solution (?) for every problem

difficulties:
- hardware new and limited access
- language new, not widely adopted, very limited documentation

We identify following research questions:
\begin{itemize}
    \item How can 2D star-shaped stencils be mapped efficiently to the Cerebras \ac{wse}-Architecture and what are the key design choices?
    \item How does the performance of a specialized (radius 1, non-tiled) implementation scale compared to a generalized (tiled, variable radius) implementation on the \ac{wse}?
    \item How does the performance of the Cerepbras-Implentation position itself compared to highly optimized implementations on traditional \ac{hpc}-Arcitectures (\ac{cpu}, \ac{gpu})? 
\end{itemize}

The main contributions of this thesis are::
\begin{itemize}
    \item The design, implementation, and analysis of two distinct implementations for 2D star-shaped stencils on the Cerebras \ac{wse}:
    \begin{itemize}
        \item A latency-optimized, directly-mapped implementation for radius-1 stencils.
        \item A flexible, tiled implementation for varibale-radius stencils.
    \end{itemize}
    \item A detailed performance analysis comparing the two implementations and investigating the tiled algorithms parameter space. 
    \item A performance comparison of the \ac{wse}-implementations with highly optimized, devito generated code for modern multi core \acp{cpu} and high-end \acp{gpu}.
    \item A simplified performance model for the implemented stencil operators on the \ac{wse}, which accounts for key architectural features.
\end{itemize} 